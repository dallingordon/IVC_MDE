{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be4fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from torchvision import models\n",
    "import tqdm\n",
    "from torchvision.transforms import ToTensor\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize, Compose, ToPILImage, ToTensor\n",
    "import pickle\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "#from kornia.filters import SpatialGradient\n",
    "\n",
    "import random\n",
    "from torchvision.transforms import RandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbe4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu_block(in_channel,out_channel,kernel,padding):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_channel,out_channel, kernel_size = kernel, padding=padding),\n",
    "            nn.ReLU()) #nn.ReLU(inplace=True) #nn.Ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c7ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanilla_unet_full(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        self.input_1 = conv_relu_block(3,3,3,1) ##grayscale inputs\n",
    "        #self.input_2 = conv_relu_block(64, 64, 3, 1) #no extra channels\n",
    "\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.l0 = nn.Sequential(*self.base_layers[:3])\n",
    "        self.U0_conv = conv_relu_block(64, 64, 1, 0)\n",
    "        self.conv_up0 = conv_relu_block(64 + 256, 128, 3, 0)\n",
    "\n",
    "        self.l1 = nn.Sequential(*self.base_layers[3:5])\n",
    "        self.U1_conv = conv_relu_block(64, 64, 1, 0)\n",
    "        self.conv_up1 = conv_relu_block(64 + 256, 256, 3, 1)\n",
    "\n",
    "        self.l2 = self.base_layers[5]\n",
    "        self.U2_conv = conv_relu_block(128, 128, 1, 0)\n",
    "        self.conv_up2 = conv_relu_block(128 + 512, 256, 3, 1)\n",
    "\n",
    "        self.l3 = self.base_layers[6]\n",
    "        self.U3_conv = conv_relu_block(256, 256, 1, 0)\n",
    "        self.conv_up3 = conv_relu_block(256 + 512, 512, 3, 1)\n",
    "\n",
    "        self.l4 = self.base_layers[7]\n",
    "        self.U4_conv = conv_relu_block(512, 512, 1, 0)\n",
    "\n",
    "        self.conv_up4 = conv_relu_block(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.out4 = nn.Conv2d(128, n_class, 1)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x, SAM):\n",
    "        x = torch.cat([x,SAM,x], axis = 1)\n",
    "        x = self.input_1(x)\n",
    "        \n",
    "        #print(x.shape,'x')\n",
    "         #concat on channel\n",
    "        #x_one = self.input_2(x_one)\n",
    "        block0 = self.l0(x)\n",
    "        block1 = self.l1(block0)\n",
    "        block2 = self.l2(block1)\n",
    "        block3 = self.l3(block2)\n",
    "        block4 = self.l4(block3)\n",
    "\n",
    "        block4 = self.U4_conv(block4)\n",
    "        #print(block4.shape)\n",
    "        x = nn.Upsample(size = (138,97), mode='bilinear', align_corners=True)(block4)\n",
    "        block3 = self.U3_conv(block3)\n",
    "        \n",
    "        x = torch.cat([x, block3], axis=1)\n",
    "        x = self.conv_up3(x)\n",
    "        \n",
    "        x = nn.Upsample(size = (275,194), mode='bilinear', align_corners=True)(x)\n",
    "        \n",
    "        block2 = self.U2_conv(block2)\n",
    "        \n",
    "        #print(x.shape, block2.shape)\n",
    "        x = torch.cat([x, block2], axis=1)\n",
    "        \n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = nn.Upsample(size = (550,388), mode='bilinear', align_corners=True)(x)\n",
    "        block1 = self.U1_conv(block1)\n",
    "        #print(x.shape, block1.shape)\n",
    "        \n",
    "        x = torch.cat([x, block1], axis=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = nn.Upsample(size = (1100, 775), mode='bilinear', align_corners=True)(x) \n",
    "        block0 = self.U0_conv(block0)\n",
    "\n",
    "        #print(x.shape, block0.shape)\n",
    "        x = torch.cat([x, block0], axis=1)\n",
    "        x = self.conv_up0(x)\n",
    "        out4 = self.out4(x)\n",
    "\n",
    "        out4_upsampled = F.interpolate(out4, size=(2200,1550), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        relu = nn.ReLU()\n",
    "        out = relu(out4_upsampled)\n",
    "        \n",
    "        \n",
    "        return out4_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4701b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a9c91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vanilla_unet_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/7366686.1.p100/ipykernel_19869/4228171167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvanilla_unet_full\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'../../nkono/IVC_MDE/unet_sam.pt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vanilla_unet_full' is not defined"
     ]
    }
   ],
   "source": [
    "model_list = [vanilla_unet_full]\n",
    "model_path_list = ['../../nkono/IVC_MDE/unet_sam.pt'] \n",
    "\n",
    "sam = True\n",
    "\n",
    "\n",
    "\n",
    "for j, model in enumerate(model_list):\n",
    "    \n",
    "    num_samples = len(model_list)\n",
    "    \n",
    "    silog = np.zeros(num_samples, np.float32)\n",
    "    log10 = np.zeros(num_samples, np.float32)\n",
    "    rms = np.zeros(num_samples, np.float32)\n",
    "    log_rms = np.zeros(num_samples, np.float32)\n",
    "    abs_rel = np.zeros(num_samples, np.float32)\n",
    "    sq_rel = np.zeros(num_samples, np.float32)\n",
    "    d1 = np.zeros(num_samples, np.float32)\n",
    "    d2 = np.zeros(num_samples, np.float32)\n",
    "    d3 = np.zeros(num_samples, np.float32)\n",
    "    \n",
    "    model = model_list[j](5)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path_list[j]))\n",
    "    model.to(device)\n",
    "\n",
    "    in_path = \"../../jkoh/inputs/\"\n",
    "    y_path = '../../jkoh/depth_annotations/'\n",
    "    dir_list = os.listdir(in_path)\n",
    "    d_paths = [(in_path+v,y_path+v) for v in dir_list]\n",
    "    \n",
    "    if sam:\n",
    "        sam_dir = \"sam_outputs/val_mask/\"\n",
    "        sam_paths = [(sam_dir+v) for v in dir_list]\n",
    "    \n",
    "    silog = [] \n",
    "    for i,path in enumerate(d_paths):\n",
    "        image = Image.open(path[0])\n",
    "        dt_depth = Image.open(path[1])\n",
    "        \n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        if sam:\n",
    "            sam_output = Image.open(sam_paths[i])\n",
    "            sam_output = transform(sam_output).unsqueeze(0).to(device)\n",
    "       \n",
    "            outputs = model(image, sam_output)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            outputs = model(image)\n",
    "        I\n",
    "        \n",
    "        silog[i], log10[i], abs_rel[i], sq_rel[i], rms[i], log_rms[i], d1[i], d2[i], d3[i] = compute_errors(gt_depth, pred_depth)\n",
    "        \n",
    "    print(\"{:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}\".format('silog', 'abs_rel', 'log10', 'rms',\n",
    "                                                                                 'sq_rel', 'log_rms', 'd1', 'd2', 'd3'))\n",
    "    print(\"{:7.4f}, {:7.4f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}\".format(\n",
    "        silog.mean(), abs_rel.mean(), log10.mean(), rms.mean(), sq_rel.mean(), log_rms.mean(), d1.mean(), d2.mean(),\n",
    "        d3.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bee12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.vanilla_unet_full"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f0286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

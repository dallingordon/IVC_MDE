{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b88fa9",
   "metadata": {
    "id": "38b88fa9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from torchvision import models\n",
    "import tqdm\n",
    "\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize, Compose, ToPILImage, ToTensor\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "#from kornia.filters import SpatialGradient\n",
    "\n",
    "import random\n",
    "from torchvision.transforms import RandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "YAFmAijBUCp3",
   "metadata": {
    "id": "YAFmAijBUCp3"
   },
   "outputs": [],
   "source": [
    "patch_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d30c88ba",
   "metadata": {
    "id": "d30c88ba"
   },
   "outputs": [],
   "source": [
    "class MonocularDepthDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, crop_size=patch_size):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['image']\n",
    "        depth_path = self.df.iloc[idx]['depth']\n",
    "\n",
    "        image = Image.open(image_path) ##no rgb, takes grayscale\n",
    "        depth = Image.open(depth_path)\n",
    "\n",
    "        # randomly crop image and depth\n",
    "        i, j, h, w = RandomCrop.get_params(image, output_size=(self.crop_size[0], self.crop_size[1]))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        depth = TF.crop(depth, i, j, h, w)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            depth = self.transform(depth)\n",
    "\n",
    "        return image, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd2d69bc",
   "metadata": {
    "id": "dd2d69bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gradient_loss_fn(gen_frames, gt_frames, alpha=1):\n",
    "    def gradient(x):\n",
    "        # idea from tf.image.image_gradients(image)\n",
    "        # https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/image_ops_impl.py#L3441-L3512\n",
    "        # x: (b,c,h,w), float32 or float64\n",
    "        # dx, dy: (b,c,h,w)\n",
    "\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        # gradient step=1\n",
    "        left = x\n",
    "        right = F.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = F.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        # dx, dy = torch.abs(right - left), torch.abs(bottom - top)\n",
    "        dx, dy = right - left, bottom - top \n",
    "        # dx will always have zeros in the last column, right-left\n",
    "        # dy will always have zeros in the last row,    bottom-top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return dx, dy\n",
    "\n",
    "    # gradient\n",
    "    gen_dx, gen_dy = gradient(gen_frames)\n",
    "    gt_dx, gt_dy = gradient(gt_frames)\n",
    "    #\n",
    "    grad_diff_x = torch.abs(gt_dx - gen_dx)\n",
    "    grad_diff_y = torch.abs(gt_dy - gen_dy)\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return torch.mean(grad_diff_x ** alpha + grad_diff_y ** alpha)\n",
    "\n",
    "class DepthEstimationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(DepthEstimationLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def forward(self, pred_depth, true_depth):\n",
    "        pred_depth = torch.clamp(pred_depth, min=1e-8)\n",
    "        true_depth = torch.clamp(true_depth, min=1e-8)\n",
    "\n",
    "        # Scale-invariant MSE loss\n",
    "        diff = torch.log(pred_depth) - torch.log(true_depth)\n",
    "        mse_loss = torch.mean(diff**2)\n",
    "        #scale_invariant_mse_loss = mse_loss - (self.alpha * (torch.sum(diff)**2)) / (true_depth.numel()**2)\n",
    "\n",
    "    \n",
    "\n",
    "        #gradient_loss = gradient_loss_fn(pred_depth,true_depth,alpha=self.alpha)\n",
    "\n",
    "        #total_loss = (scale_invariant_mse_loss + gradient_loss)/2\n",
    "\n",
    "        return (torch.sum((pred_depth - true_depth)**2))**0.5#scale_invariant_mse_loss#total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5adc8983",
   "metadata": {
    "id": "5adc8983"
   },
   "outputs": [],
   "source": [
    "def conv_relu_block(in_channel,out_channel,kernel,padding):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_channel,out_channel, kernel_size = kernel, padding=padding),\n",
    "            nn.ReLU()) #nn.ReLU(inplace=True) #nn.Ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a171402",
   "metadata": {
    "id": "9a171402"
   },
   "outputs": [],
   "source": [
    "class vanilla_unet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        self.input_1 = conv_relu_block(3,3,3,1) ##grayscale inputs\n",
    "        #self.input_2 = conv_relu_block(64, 64, 3, 1) #no extra channels\n",
    "\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.l0 = nn.Sequential(*self.base_layers[:3])\n",
    "        self.U0_conv = conv_relu_block(64, 64, 1, 0)\n",
    "        self.conv_up0 = conv_relu_block(64 + 256, 128, 3, 1)\n",
    "\n",
    "        self.l1 = nn.Sequential(*self.base_layers[3:5])\n",
    "        self.U1_conv = conv_relu_block(64, 64, 1, 0)\n",
    "        self.conv_up1 = conv_relu_block(64 + 256, 256, 3, 1)\n",
    "\n",
    "        self.l2 = self.base_layers[5]\n",
    "        self.U2_conv = conv_relu_block(128, 128, 1, 0)\n",
    "        self.conv_up2 = conv_relu_block(128 + 512, 256, 3, 1)\n",
    "\n",
    "        self.l3 = self.base_layers[6]\n",
    "        self.U3_conv = conv_relu_block(256, 256, 1, 0)\n",
    "        self.conv_up3 = conv_relu_block(256 + 512, 512, 3, 1)\n",
    "\n",
    "        self.l4 = self.base_layers[7]\n",
    "        self.U4_conv = conv_relu_block(512, 512, 1, 0)\n",
    "\n",
    "        self.conv_up4 = conv_relu_block(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.out4 = nn.Conv2d(128, n_class, 1)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([x,x,x], axis = 1)\n",
    "        x = self.input_1(x)\n",
    "        \n",
    "        #print(x.shape,'x')\n",
    "         #concat on channel\n",
    "        #x_one = self.input_2(x_one)\n",
    "        block0 = self.l0(x)\n",
    "        block1 = self.l1(block0)\n",
    "        block2 = self.l2(block1)\n",
    "        block3 = self.l3(block2)\n",
    "        block4 = self.l4(block3)\n",
    "        #print('b0: ', block0.shape)\n",
    "        #print('b1: ', block1.shape)\n",
    "        #print('b2: ', block2.shape)\n",
    "        #print('b3: ', block3.shape)\n",
    "        #print('b4: ', block4.shape)\n",
    "        \n",
    "\n",
    "        block4 = self.U4_conv(block4)\n",
    "        x = self.upsample(block4)\n",
    "\n",
    "        #print(block0.shape, block1.shape, block2.shape,block3.shape,block4.shape)\n",
    "        block3 = self.U3_conv(block3)\n",
    "        #print(x.shape, block3.shape)\n",
    "        x = torch.cat([x, block3], axis=1)\n",
    "        x = self.conv_up3(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        block2 = self.U2_conv(block2)\n",
    "        #print('x shape: ', x.shape)\n",
    "        #print('block2 precat: ', block2.shape)\n",
    "        x = torch.cat([x, block2], axis=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        block1 = self.U1_conv(block1)\n",
    "        x = torch.cat([x, block1], axis=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        block0 = self.U0_conv(block0)\n",
    "        x = torch.cat([x, block0], axis=1)\n",
    "        x = self.conv_up0(x)\n",
    "        out4 = self.out4(x)\n",
    "\n",
    "        out4_upsampled = F.interpolate(out4, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        #relu = nn.ReLU()\n",
    "        out = out4_upsampled#relu(out4_upsampled)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79b2a61e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79b2a61e",
    "outputId": "7e094bd1-ea9c-4437-d7f4-410df78aea12"
   },
   "outputs": [],
   "source": [
    "v = vanilla_unet(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cAWkYz_BCsCv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAWkYz_BCsCv",
    "outputId": "51998883-11b6-41bf-d1ed-489196ab132f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024])\n",
      "b0:  torch.Size([1, 64, 512, 512])\n",
      "b1:  torch.Size([1, 64, 256, 256])\n",
      "b2:  torch.Size([1, 128, 128, 128])\n",
      "b3:  torch.Size([1, 256, 64, 64])\n",
      "b4:  torch.Size([1, 512, 32, 32])\n",
      "x shape:  torch.Size([1, 512, 128, 128])\n",
      "block2 precat:  torch.Size([1, 128, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2324,  0.2753,  0.3181,  ...,  0.2258,  0.1913,  0.1567],\n",
       "          [ 0.1522,  0.1755,  0.1987,  ...,  0.1424,  0.1067,  0.0710],\n",
       "          [ 0.0720,  0.0757,  0.0793,  ...,  0.0590,  0.0221, -0.0148],\n",
       "          ...,\n",
       "          [ 0.1539,  0.1555,  0.1572,  ...,  0.1608,  0.1143,  0.0678],\n",
       "          [ 0.1300,  0.1384,  0.1468,  ...,  0.1555,  0.1270,  0.0986],\n",
       "          [ 0.1061,  0.1213,  0.1364,  ...,  0.1502,  0.1398,  0.1293]],\n",
       "\n",
       "         [[ 0.0386,  0.0779,  0.1171,  ...,  0.1012,  0.0768,  0.0524],\n",
       "          [ 0.0123,  0.0582,  0.1040,  ...,  0.0794,  0.0827,  0.0860],\n",
       "          [-0.0140,  0.0384,  0.0909,  ...,  0.0577,  0.0886,  0.1196],\n",
       "          ...,\n",
       "          [ 0.0289,  0.0508,  0.0728,  ...,  0.0127,  0.0350,  0.0573],\n",
       "          [ 0.0424,  0.0579,  0.0733,  ...,  0.0497,  0.0531,  0.0564],\n",
       "          [ 0.0560,  0.0649,  0.0737,  ...,  0.0867,  0.0711,  0.0555]],\n",
       "\n",
       "         [[-0.0288,  0.0238,  0.0764,  ...,  0.0560,  0.0364,  0.0169],\n",
       "          [-0.0580,  0.0121,  0.0823,  ...,  0.0345,  0.0087, -0.0171],\n",
       "          [-0.0872,  0.0005,  0.0881,  ...,  0.0131, -0.0190, -0.0510],\n",
       "          ...,\n",
       "          [ 0.0140,  0.0563,  0.0986,  ...,  0.0224,  0.0085, -0.0054],\n",
       "          [-0.0233,  0.0106,  0.0444,  ...,  0.0101,  0.0028, -0.0044],\n",
       "          [-0.0605, -0.0351, -0.0097,  ..., -0.0023, -0.0029, -0.0035]],\n",
       "\n",
       "         [[ 0.0294, -0.0619, -0.1532,  ..., -0.0446, -0.0034,  0.0379],\n",
       "          [ 0.0316, -0.0257, -0.0829,  ...,  0.0078,  0.0376,  0.0675],\n",
       "          [ 0.0339,  0.0106, -0.0126,  ...,  0.0602,  0.0786,  0.0970],\n",
       "          ...,\n",
       "          [ 0.0531, -0.0093, -0.0718,  ..., -0.0412, -0.0084,  0.0245],\n",
       "          [ 0.0485, -0.0098, -0.0681,  ..., -0.0431, -0.0145,  0.0141],\n",
       "          [ 0.0439, -0.0102, -0.0644,  ..., -0.0451, -0.0207,  0.0037]],\n",
       "\n",
       "         [[-0.1380, -0.1496, -0.1611,  ..., -0.0893, -0.1293, -0.1692],\n",
       "          [-0.1255, -0.1524, -0.1792,  ..., -0.0635, -0.0902, -0.1170],\n",
       "          [-0.1130, -0.1552, -0.1974,  ..., -0.0376, -0.0512, -0.0648],\n",
       "          ...,\n",
       "          [-0.1490, -0.1434, -0.1379,  ..., -0.0710, -0.0520, -0.0331],\n",
       "          [-0.1219, -0.1243, -0.1268,  ..., -0.0556, -0.0389, -0.0222],\n",
       "          [-0.0948, -0.1052, -0.1157,  ..., -0.0403, -0.0258, -0.0114]]]],\n",
       "       grad_fn=<UpsampleBilinear2DBackward1>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((1,1,patch_size[0],patch_size[1]))\n",
    "#print(x.shape)\n",
    "v.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a763a865",
   "metadata": {
    "id": "a763a865",
    "outputId": "9168409b-099c-4e2a-83fc-06220919b439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#model = depth_model(num_classes=1).to('cuda')\n",
    "#model = resunet(n_class=1).to('cuda')\n",
    "model = vanilla_unet(n_class=1).to('cuda')\n",
    "\n",
    "#model = effunet(n_class=1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "221e4ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projectnb/cs585bp/krishna/project\n"
     ]
    }
   ],
   "source": [
    "cd ../../krishna/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49976db4",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "77245589ab5e45a5adcf2e370a151190",
      "1d75becdfe22406e8ac99ee0229a7892"
     ]
    },
    "id": "49976db4",
    "outputId": "9af91597-7ddd-43b9-ea2b-b84880e9d000"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/7274861.1.academic-gpu/ipykernel_226164/1656412895.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm.tqdm_notebook(range(num_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c30a3b8843b4327b567f03e5f68136a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/7274861.1.academic-gpu/ipykernel_226164/1656412895.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for images, depths in tqdm.tqdm_notebook(train_dataloader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4dfb90a85e4450aa47d411e412bc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1523079.0421316964\n",
      "tensor([[[[225.9700, 299.2883, 372.6066,  ..., 399.8113, 320.6970, 241.5827],\n",
      "          [296.3044, 393.2942, 490.2840,  ..., 527.6954, 423.2629, 318.8303],\n",
      "          [366.6387, 487.3001, 607.9614,  ..., 655.5797, 525.8288, 396.0779],\n",
      "          ...,\n",
      "          [402.1918, 532.0461, 661.9005,  ..., 627.2892, 504.0517, 380.8141],\n",
      "          [324.9572, 429.4845, 534.0118,  ..., 504.5987, 405.5048, 306.4109],\n",
      "          [247.7227, 326.9229, 406.1231,  ..., 381.9081, 306.9579, 232.0077]]],\n",
      "\n",
      "\n",
      "        [[[230.1348, 304.7097, 379.2845,  ..., 397.3133, 319.5917, 241.8702],\n",
      "          [302.3275, 401.2037, 500.0799,  ..., 524.8654, 422.1418, 319.4181],\n",
      "          [374.5204, 497.6978, 620.8752,  ..., 652.4176, 524.6918, 396.9661],\n",
      "          ...,\n",
      "          [359.4037, 477.4421, 595.4806,  ..., 637.5113, 512.9872, 388.4631],\n",
      "          [289.6819, 384.6567, 479.6316,  ..., 513.2006, 413.0503, 312.9001],\n",
      "          [219.9601, 291.8713, 363.7825,  ..., 388.8900, 313.1135, 237.3370]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9d0526394e427e882f1e32be28c035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1474671.5248325893\n",
      "tensor([[[[231.9027, 301.5659, 371.2292,  ..., 380.2215, 309.5569, 238.8922],\n",
      "          [299.2137, 389.5897, 479.9656,  ..., 492.2044, 400.6057, 309.0069],\n",
      "          [366.5248, 477.6134, 588.7020,  ..., 604.1873, 491.6545, 379.1217],\n",
      "          ...,\n",
      "          [383.2927, 495.1938, 607.0948,  ..., 570.9784, 465.0889, 359.1995],\n",
      "          [315.8765, 407.8130, 499.7496,  ..., 465.2250, 379.0339, 292.8427],\n",
      "          [248.4602, 320.4323, 392.4044,  ..., 359.4717, 292.9788, 226.4859]]],\n",
      "\n",
      "\n",
      "        [[[235.9197, 305.9644, 376.0091,  ..., 369.1043, 300.9142, 232.7242],\n",
      "          [304.3523, 395.1953, 486.0382,  ..., 477.0979, 388.8683, 300.6386],\n",
      "          [372.7849, 484.4261, 596.0673,  ..., 585.0914, 476.8222, 368.5530],\n",
      "          ...,\n",
      "          [345.5391, 449.8457, 554.1523,  ..., 590.8282, 481.7087, 372.5893],\n",
      "          [281.0870, 365.7562, 450.4255,  ..., 482.3787, 393.3954, 304.4121],\n",
      "          [216.6349, 281.6668, 346.6986,  ..., 373.9292, 305.0820, 236.2348]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d0a23c75794c78a7004f96327b6d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1467518.6082589286\n",
      "tensor([[[[344.5898, 437.2983, 530.0067,  ..., 528.1404, 435.0603, 341.9802],\n",
      "          [435.0442, 553.0107, 670.9772,  ..., 670.5991, 552.5226, 434.4462],\n",
      "          [525.4985, 668.7231, 811.9476,  ..., 813.0578, 669.9850, 526.9122],\n",
      "          ...,\n",
      "          [488.5919, 622.8073, 757.0226,  ..., 749.3574, 618.4691, 487.5807],\n",
      "          [398.8768, 508.2958, 617.7148,  ..., 617.5297, 509.7918, 402.0539],\n",
      "          [309.1617, 393.7844, 478.4072,  ..., 485.7020, 401.1145, 316.5271]]],\n",
      "\n",
      "\n",
      "        [[[344.4405, 439.4238, 534.4072,  ..., 510.6799, 420.9977, 331.3156],\n",
      "          [435.6964, 556.7875, 677.8787,  ..., 645.9640, 532.5869, 419.2097],\n",
      "          [526.9523, 674.1512, 821.3502,  ..., 781.2481, 644.1760, 507.1039],\n",
      "          ...,\n",
      "          [491.3010, 625.2368, 759.1727,  ..., 743.5405, 614.4948, 485.4492],\n",
      "          [403.1658, 512.7901, 622.4144,  ..., 613.4611, 507.1001, 400.7392],\n",
      "          [315.0306, 400.3434, 485.6561,  ..., 483.3817, 399.7054, 316.0291]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e90c102a134757a8ac6107a1e3b83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1463779.0066964286\n",
      "tensor([[[[306.9858, 388.9007, 470.8156,  ..., 480.5141, 396.9550, 313.3960],\n",
      "          [385.1759, 488.5612, 591.9464,  ..., 605.3864, 500.1345, 394.8826],\n",
      "          [463.3661, 588.2217, 713.0773,  ..., 730.2586, 603.3140, 476.3693],\n",
      "          ...,\n",
      "          [490.1723, 621.2407, 752.3091,  ..., 748.0969, 619.2391, 490.3813],\n",
      "          [405.6099, 513.9461, 622.2823,  ..., 616.6927, 510.7030, 404.7133],\n",
      "          [321.0475, 406.6516, 492.2556,  ..., 485.2885, 402.1669, 319.0453]]],\n",
      "\n",
      "\n",
      "        [[[360.3994, 458.9185, 557.4376,  ..., 436.1145, 359.6198, 283.1252],\n",
      "          [452.9656, 576.6262, 700.2866,  ..., 548.2275, 452.0008, 355.7741],\n",
      "          [545.5317, 694.3337, 843.1357,  ..., 660.3405, 544.3817, 428.4230],\n",
      "          ...,\n",
      "          [496.9497, 630.9760, 765.0023,  ..., 840.9426, 695.8099, 550.6772],\n",
      "          [409.7520, 520.2670, 630.7820,  ..., 695.8018, 575.5226, 455.2434],\n",
      "          [322.5544, 409.5580, 496.5616,  ..., 550.6611, 455.2353, 359.8095]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e8750f36644e98ae8941090a62034f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1458216.4210379464\n",
      "tensor([[[[388.8443, 485.8908, 582.9374,  ..., 535.7897, 443.3846, 350.9795],\n",
      "          [482.5026, 603.0693, 723.6360,  ..., 666.7281, 552.2145, 437.7008],\n",
      "          [576.1608, 720.2477, 864.3346,  ..., 797.6667, 661.0444, 524.4221],\n",
      "          ...,\n",
      "          [519.9626, 655.4701, 790.9776,  ..., 804.8029, 671.1104, 537.4180],\n",
      "          [430.2531, 542.1044, 653.9557,  ..., 669.9803, 558.5977, 447.2151],\n",
      "          [340.5435, 428.7386, 516.9337,  ..., 535.1578, 446.0851, 357.0122]]],\n",
      "\n",
      "\n",
      "        [[[373.7723, 469.3964, 565.0204,  ..., 553.0355, 460.9529, 368.8703],\n",
      "          [465.5296, 584.9773, 704.4249,  ..., 685.6057, 571.8902, 458.1747],\n",
      "          [557.2869, 700.5582, 843.8293,  ..., 818.1758, 682.8275, 547.4792],\n",
      "          ...,\n",
      "          [569.8797, 704.7126, 839.5454,  ..., 803.2651, 670.7146, 538.1641],\n",
      "          [477.3312, 590.3796, 703.4279,  ..., 668.4232, 558.1406, 447.8582],\n",
      "          [384.7827, 476.0465, 567.3103,  ..., 533.5812, 445.5667, 357.5522]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f709410e4948adb14b4d729a459dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1480732.0301339286\n",
      "tensor([[[[462.1521, 566.7400, 671.3279,  ..., 611.2800, 513.0312, 414.7823],\n",
      "          [562.5982, 689.0969, 815.5957,  ..., 741.1384, 622.9814, 504.8244],\n",
      "          [663.0443, 811.4539, 959.8635,  ..., 870.9968, 732.9316, 594.8665],\n",
      "          ...,\n",
      "          [665.6561, 807.9935, 950.3309,  ..., 853.2244, 724.0930, 594.9614],\n",
      "          [561.4126, 682.1464, 802.8802,  ..., 719.5746, 610.2693, 500.9641],\n",
      "          [457.1691, 556.2993, 655.4296,  ..., 585.9247, 496.4458, 406.9668]]],\n",
      "\n",
      "\n",
      "        [[[467.1220, 573.3644, 679.6069,  ..., 634.4144, 534.9733, 435.5323],\n",
      "          [569.4924, 698.4490, 827.4056,  ..., 766.2242, 647.6335, 529.0428],\n",
      "          [671.8627, 823.5335, 975.2043,  ..., 898.0340, 760.2937, 622.5533],\n",
      "          ...,\n",
      "          [600.7769, 734.7234, 868.6700,  ..., 855.2563, 725.0364, 594.8165],\n",
      "          [501.4323, 613.3328, 725.2334,  ..., 721.0593, 610.8246, 500.5899],\n",
      "          [402.0877, 491.9422, 581.7968,  ..., 586.8623, 496.6128, 406.3634]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c077dfa4ce4897bdb7032b38f1761b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1467009.1509486607\n",
      "tensor([[[[367.5177, 453.5918, 539.6659,  ..., 528.4523, 443.1931, 357.9339],\n",
      "          [451.6865, 557.2608, 662.8350,  ..., 647.5078, 543.5438, 439.5798],\n",
      "          [535.8553, 660.9297, 786.0042,  ..., 766.5632, 643.8945, 521.2258],\n",
      "          ...,\n",
      "          [511.0103, 627.9118, 744.8134,  ..., 707.9538, 594.2532, 480.5525],\n",
      "          [427.0215, 524.9450, 622.8686,  ..., 592.2486, 496.9713, 401.6940],\n",
      "          [343.0327, 421.9782, 500.9238,  ..., 476.5433, 399.6894, 322.8355]]],\n",
      "\n",
      "\n",
      "        [[[388.1499, 478.6607, 569.1715,  ..., 530.0013, 443.3775, 356.7536],\n",
      "          [475.7424, 586.4191, 697.0958,  ..., 649.4852, 543.5722, 437.6592],\n",
      "          [563.3348, 694.1774, 825.0201,  ..., 768.9691, 643.7669, 518.5647],\n",
      "          ...,\n",
      "          [567.3347, 698.9513, 830.5681,  ..., 783.9352, 660.5084, 537.0815],\n",
      "          [476.5744, 587.7206, 698.8669,  ..., 656.6927, 553.4061, 450.1196],\n",
      "          [385.8141, 476.4899, 567.1657,  ..., 529.4503, 446.3040, 363.1576]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5839baf30c4e53acc71d06963e48f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1465814.258091518\n",
      "tensor([[[[394.7250, 481.3030, 567.8811,  ..., 546.9627, 460.9466, 374.9305],\n",
      "          [478.3272, 582.6714, 687.0155,  ..., 662.1572, 558.5892, 455.0210],\n",
      "          [561.9295, 684.0397, 806.1500,  ..., 777.3518, 656.2317, 535.1116],\n",
      "          ...,\n",
      "          [524.8081, 637.8411, 750.8741,  ..., 788.5690, 669.7343, 550.8996],\n",
      "          [440.8127, 536.1132, 631.4137,  ..., 665.0012, 564.3863, 463.7714],\n",
      "          [356.8173, 434.3853, 511.9532,  ..., 541.4335, 459.0383, 376.6431]]],\n",
      "\n",
      "\n",
      "        [[[394.2775, 481.0466, 567.8157,  ..., 607.6087, 514.9890, 422.3692],\n",
      "          [477.8984, 582.5421, 687.1858,  ..., 733.4951, 623.4977, 513.5003],\n",
      "          [561.5193, 684.0376, 806.5559,  ..., 859.3815, 732.0065, 604.6315],\n",
      "          ...,\n",
      "          [616.2441, 747.1074, 877.9706,  ..., 814.4071, 692.3724, 570.3377],\n",
      "          [522.8502, 635.0223, 747.1943,  ..., 691.0732, 586.9860, 482.8987],\n",
      "          [429.4564, 522.9371, 616.4179,  ..., 567.7394, 481.5996, 395.4598]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72c7ddc69941d0b66a5f2466fe4e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1473001.5968191964\n",
      "tensor([[[[424.9778, 515.8203, 606.6627,  ..., 568.1049, 482.4688, 396.8328],\n",
      "          [513.2971, 622.1977, 731.0983,  ..., 685.2303, 583.3552, 481.4799],\n",
      "          [601.6164, 728.5751, 855.5338,  ..., 802.3558, 684.2415, 566.1271],\n",
      "          ...,\n",
      "          [525.1988, 634.2861, 743.3735,  ..., 763.6105, 651.1446, 538.6787],\n",
      "          [442.4278, 534.7995, 627.1713,  ..., 646.3289, 550.7292, 455.1296],\n",
      "          [359.6567, 435.3129, 510.9691,  ..., 529.0474, 450.3139, 371.5805]]],\n",
      "\n",
      "\n",
      "        [[[406.9640, 493.1806, 579.3972,  ..., 524.1158, 444.2903, 364.4648],\n",
      "          [492.2733, 595.6853, 699.0973,  ..., 629.3607, 534.4484, 439.5363],\n",
      "          [577.5826, 698.1900, 818.7974,  ..., 734.6055, 624.6066, 514.6077],\n",
      "          ...,\n",
      "          [620.3486, 758.2371, 896.1256,  ..., 720.1153, 612.7184, 505.3216],\n",
      "          [525.8380, 644.1166, 762.3951,  ..., 609.7502, 518.4512, 427.1523],\n",
      "          [431.3274, 529.9960, 628.6646,  ..., 499.3850, 424.1841, 348.9830]]]],\n",
      "       device='cuda:0', grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff498161c624a0dad0cfa32f1ee4ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  1475661.4481026786\n",
      "tensor([[[[ 519.4010,  628.2874,  737.1738,  ...,  689.0264,  587.6663,\n",
      "            486.3061],\n",
      "          [ 623.0278,  752.8343,  882.6408,  ...,  826.3239,  706.7734,\n",
      "            587.2228],\n",
      "          [ 726.6545,  877.3811, 1028.1078,  ...,  963.6213,  825.8804,\n",
      "            688.1396],\n",
      "          ...,\n",
      "          [ 665.1313,  798.4329,  931.7346,  ...,  895.6385,  764.7383,\n",
      "            633.8381],\n",
      "          [ 562.1439,  675.7933,  789.4428,  ...,  760.2930,  648.4470,\n",
      "            536.6010],\n",
      "          [ 459.1565,  553.1538,  647.1511,  ...,  624.9475,  532.1558,\n",
      "            439.3640]]],\n",
      "\n",
      "\n",
      "        [[[ 498.7350,  603.8744,  709.0139,  ...,  700.3795,  596.3596,\n",
      "            492.3397],\n",
      "          [ 601.0522,  725.8787,  850.7052,  ...,  842.1880,  718.9941,\n",
      "            595.8004],\n",
      "          [ 703.3694,  847.8830,  992.3966,  ...,  983.9965,  841.6287,\n",
      "            699.2610],\n",
      "          ...,\n",
      "          [ 653.9136,  780.7143,  907.5150,  ...,  953.2515,  816.7070,\n",
      "            680.1625],\n",
      "          [ 552.4205,  660.7664,  769.1123,  ...,  812.3445,  695.1786,\n",
      "            578.0128],\n",
      "          [ 450.9274,  540.8185,  630.7096,  ...,  671.4374,  573.6502,\n",
      "            475.8630]]]], device='cuda:0',\n",
      "       grad_fn=<UpsampleBilinear2DBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters, dataset paths, and other configurations\n",
    "batch_size = 8\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(patch_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "train_dataset = MonocularDepthDataset(df, transform = transform)\n",
    "#val_dataset = MonocularDepthDataset(val_image_paths, val_depth_paths, transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12)\n",
    "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "criterion = DepthEstimationLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in tqdm.tqdm_notebook(range(num_epochs)):\n",
    "    #train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, depths in tqdm.tqdm_notebook(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        depths = depths.to(device)\n",
    "        \n",
    "        mask = depths == 0\n",
    "        f_img\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs[-1].float(), depths.float())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    print('Training loss: ', train_loss)\n",
    "    print(outputs)\n",
    "    #val_loss = validate(model, val_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../../nkono/IVC_MDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96406b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'good_small_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294280fd",
   "metadata": {
    "id": "294280fd"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31ea2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
